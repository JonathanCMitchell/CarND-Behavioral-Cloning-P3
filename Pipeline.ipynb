{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mannie_recovery\u001b[0m/               data_acquisition.ipynb       \u001b[01;34mrecovery_laps_more\u001b[0m/\r\n",
      "\u001b[01;34mCarND-Behavioral-Cloning-P3\u001b[0m/  data_acquisition_method.txt  training_data_clr.p\r\n",
      "clone-personal.ipynb          model1.h5                    training_data_g.p\r\n",
      "\u001b[01;34mdata\u001b[0m/                         model-weights1.h5            training_data.p\r\n",
      "\u001b[01;34mdata_ac\u001b[0m/                      Pipeline.ipynb               tree.txt\r\n",
      "\u001b[01;34mData_ac_backwards_training\u001b[0m/   \u001b[01;34mrecover_laps_backwards_2\u001b[0m/\r\n",
      "\u001b[01;34mData_Acquisition_2\u001b[0m/           \u001b[01;34mrecovery_laps\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('training_data_clr.p', 'rb') as handle:\n",
    "    training_data = pickle.load(handle)\n",
    "    df = pd.DataFrame.from_dict(training_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_data, X_valid_data = train_test_split(df, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50370\n",
      "40296\n",
      "10074\n"
     ]
    }
   ],
   "source": [
    "df.head(10)\n",
    "print(len(df))\n",
    "print(len(X_train_data))\n",
    "print(len(X_valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>steer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42733</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/data/IMG...</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16455</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/data/IMG...</td>\n",
       "      <td>-0.028302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20889</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/data_ac/...</td>\n",
       "      <td>-0.056604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/recovery...</td>\n",
       "      <td>-0.081132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45764</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/data/IMG...</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50120</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/data/IMG...</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7926</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/annie_re...</td>\n",
       "      <td>-0.037736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31734</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/data/IMG...</td>\n",
       "      <td>0.090466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26328</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/data/IMG...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>/home/jj/Documents/Behavioral_Cloning/Data_ac_...</td>\n",
       "      <td>0.094340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image     steer\n",
       "42733  /home/jj/Documents/Behavioral_Cloning/data/IMG...  0.100000\n",
       "16455  /home/jj/Documents/Behavioral_Cloning/data/IMG... -0.028302\n",
       "20889  /home/jj/Documents/Behavioral_Cloning/data_ac/... -0.056604\n",
       "5870   /home/jj/Documents/Behavioral_Cloning/recovery... -0.081132\n",
       "45764  /home/jj/Documents/Behavioral_Cloning/data/IMG... -0.100000\n",
       "50120  /home/jj/Documents/Behavioral_Cloning/data/IMG... -0.100000\n",
       "7926   /home/jj/Documents/Behavioral_Cloning/annie_re... -0.037736\n",
       "31734  /home/jj/Documents/Behavioral_Cloning/data/IMG...  0.090466\n",
       "26328  /home/jj/Documents/Behavioral_Cloning/data/IMG...  0.000000\n",
       "1842   /home/jj/Documents/Behavioral_Cloning/Data_ac_...  0.094340"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View histogram of steering angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff60d6e6668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAFkCAYAAAAzGHFUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3XucHWWd5/HPL0CIHUwiNCTcIvfY6yiS5hLWJcDgEgVk\nWBSGdiKgKzeRxShjXEYl4qAYlc4gwjDgiHLpHUTAC5EAGm9cRxIRtYOoaMslgYbQMIlNIHn2j6qO\nJ4fuJOf06T6nqz/v1+u8yKl6qupXRSX97arnqYqUEpIkSUUwpt4FSJIk1YrBRpIkFYbBRpIkFYbB\nRpIkFYbBRpIkFYbBRpIkFYbBRpIkFYbBRpIkFYbBRpIkFYbBRpIkFUbdg01E/N+IeCAiXoiIFRFx\nS0Ts00+7CyPiyYhYHRF3RsReZfO3joivRER3RLwYETdFxA5lbV4XEddHRE9ErIyIqyNifFmbXSPi\ntohYFRHLI2J+RNT9OEmSpE1rhB/YhwBfBg4C3gZsBdwREa/paxARc4EPAacDBwKrgEURMbZkPQuA\no4F3ATOBnYBvlW3rBqAFOCJvOxO4smQ7Y4CFwJbADOAU4FTgwprsqSRJGlLRaC/BjIhm4GlgZkrp\nZ/m0J4EvpJTa8+8TgBXAKSmlG/PvzwAnpZRuydtMAzqBGSmlByKiBfg10JpSWpq3mQXcBuySUloe\nEe8AvgPsmFLqztucAVwMbJ9SemWYDoMkSapCI1yxKTcJSMBzABGxOzAF+EFfg5TSC8D9wMH5pP3J\nrrKUtnkE6CppMwNY2Rdqcnfl2zqopM3DfaEmtwiYCLyxBvsmSZKG0Jb1LqBURATZLaWfpZR+k0+e\nQhY+VpQ1X5HPA5gMrMkDz0BtppBdCVovpbQ2Ip4ra9PfdvrmPdRPzdsBs4A/Ar0b2T1JkrShccBu\nwKKU0rO1WGFDBRvgcuC/AW+tdyEVmAVcX+8iJEkawf6BrB/soDVMsImIy4CjgENSSk+VzFoOBNlV\nmdKrKZOBpSVtxkbEhLKrNpPzeX1tykdJbQFsW9bmgLLSJpfM688fAa677jpaWloG2j2VmTNnDu3t\n7fUuY8TxuFXOY1Ydj1vlPGaV6+zsZPbs2ZD/LK2Fhgg2eaj5O+DQlFJX6byU0mMRsZxsJNMv8/YT\nyPrFfCVv9iDwSt6mtPPwVODevM29wKSI2K+kn80RZKHp/pI250dEc0k/myOBHqDv1li5XoCWlham\nT59exd6PThMnTvR4VcHjVjmPWXU8bpXzmA1Kzbpy1D3YRMTlQBtwLLAqIvqukPSklPp2dAHwiYj4\nHVmq+wzwOPBtyDoTR8RXgUsiYiXwInApcHdK6YG8zbKIWARcFRFnAWPJhpl3pJT6rsbcQRZgrs2H\nmO+Yb+uylNLLQ3YQJElSTdQ92ABnknUO/lHZ9PcB3wBIKc2PiCayZ85MAn4KvCOltKak/RxgLXAT\nsDVwO3B22TrfA1xGNhpqXd723L6ZKaV1EXEMcAVwD9nzcq4BLhjkPkqSpGFQ92CTUtqsIecppXnA\nvI3Mfwk4J/8M1OZ5YPYmtvNn4JjNqUmSJDWWRnyOjUaBtra2epcwInncKucxq47HrXIes8bQcE8e\nHmkiYjrw4IMPPminMUmSKrBkyRJaW1sheyvAklqss+63oiRJGqyuri66u7s33VDDrrm5malTpw7b\n9gw2kqQRrauri5aWFlavXl3vUtSPpqYmOjs7hy3cGGwkSSNad3c3q1ev9kGpDajvAXzd3d0GG0mS\nKuGDUgWOipIkSQVisJEkSYVhsJEkSYVhsJEkSYVhsJEkSYXhqChJUqE1wsP7hvIhdR0dHTz99NOc\ne+65m248ChhsJEmF1dXVxbRpLfT21vfhfePGNfHII0PzkLobbriBX//61wabnMFGklRY3d3deai5\nDqjXw/s66e0d3ofUDae//OUvvOY1r6l3GevZx0aSNAq0ANPr9BlcoPqv//ovPvzhD7P77rszbtw4\nJk+ezJFHHsnSpUs5/PDDue222/jTn/7EmDFjGDNmDHvsscf6ZdesWcMFF1zA3nvvzbhx45g6dSpz\n585lzZo1r9rOddddx/77709TUxPbbbcdbW1tPP744xu0Oeyww3jzm9/MkiVLmDlzJuPHj+ef/umf\nBrV/teYVG0mSGtgZZ5zBzTffzDnnnENLSwvPPvssP/vZz1i2bBmf+MQn6Onp4YknnmDBggWklNhm\nm20ASCnxzne+k3vuuYczzjiDN7zhDTz88MO0t7fz6KOPcvPNN6/fxkUXXcSnPvUpTjrpJE477TSe\neeYZLr30Ug499FCWLl3KhAkTAIgIuru7OeqoozjppJM4+eSTmTx5cl2Oy0AMNpIkNbCFCxdy2mmn\nMX/+/PXTzjvvvPV/3nnnnXn++edpa2vbYLnrr7+eH/7wh/zkJz/h4IMPXj/9jW98I2eddRb33Xcf\nM2bMoKuri3nz5vHZz36WuXPnrm93/PHH85a3vIXLL7+cj3/84+unr1ixgiuvvJIPfOADQ7G7g2aw\nkVRojTAiBoZ2VIyKbdKkSdx///089dRT7Ljjjpu93E033URLSwv77LMPzz777Prphx9+OCklFi9e\nzIwZM/jWt75FSokTTjhhg3Y77LADe++9N4sXL94g2Gy99daceuqpNdm3oWCwkVRYjTIiBoZ2VIyK\nbf78+Zx66qnsuuuutLa2ctRRR3HyySez++67b3S5Rx99lGXLlrH99tu/al5E8PTTTwPwu9/9jnXr\n1rHXXnv1227s2LEbTNt5553ZcsvGjQ+NW5kkDVJjjIiBoo+K0dA64YQTmDlzJrfccgt33HEHX/zi\nF/n85z/PLbfcwqxZswZcbt26dbzpTW+ivb2dlNKr5u+6667r240ZM4bbb7+dMWNePaaor89On0Ya\nAdUfg42kUaBvRIw0Mk2ePJkzzzyTM888k+7ubvbbbz8uuugiZs2aRUT0u8yee+7JL3/5Sw4//PCN\nrnvPPfckpcRuu+3W71Wbkcbh3pIkNah169bxwgsvbDCtubmZnXbaiZdeegmA8ePH09PT86plTzzx\nRB5//HGuuuqqV83r7e1l9ersFu3xxx/PmDFj+PSnP91vDc8999xgd2NYecVGkjQKdI7Ibb/44ovs\nsssuvPvd72bfffdlm2224c477+TnP/85l1xyCQCtra3ceOONfPSjH+WAAw5gm2224ZhjjuG9730v\nN954I2eddRaLFy/mrW99K2vXrqWzs5NvfvOb3HHHHUyfPp099tiDf/7nf+b888/nscce47jjjuO1\nr30tf/jDH7j11ls544wz+MhHPlKrgzHkDDaSpMJqbm5m3Lgmentn17WOceOaaG5urni5pqYmzj77\nbO644w5uueWW9Z18r7jiCk4//XQAPvjBD/LQQw9xzTXXsGDBAl7/+tdzzDHHEBF8+9vfpr29nW98\n4xvceuutNDU1scceezBnzhz22Wef9duZO3cu06ZNo729nQsvvBDI+uC8/e1v59hjj92gpoFufTUK\ng40kqbCmTp3KI4901n3If7XD/bfaaisuvvhiLr744gHbNDU1ce211/Y7b4sttuC8887b4Lk3Aznu\nuOM47rjjNtpm8eLFm1xPvRlsJEmFNnXqVEejjSJ2HpYkSYVhsJEkSYVhsJEkSYVhsJEkSYVhsJEk\nSYVhsJEkSYVhsJEkSYXhc2wkSYXQ2VnP1yaoP/X4f2KwkSSNaM3NzTQ1NTF7dn1fm6D+NTVV9zqJ\nahlsJEkj2tSpU+nsrP9rE9S/al8nUS2DjSRpxPO1Cepj52FJklQYBhtJklQYBhtJklQYBhtJklQY\nBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJ\nklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQY\nBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYBhtJklQYDRFsIuKQiPhORDwREesi4tiy+V/L\np5d+Fpa12ToivhIR3RHxYkTcFBE7lLV5XURcHxE9EbEyIq6OiPFlbXaNiNsiYlVELI+I+RHREMdJ\nkiRtXKP8wB4P/AL4IJAGaPN9YDIwJf+0lc1fABwNvAuYCewEfKuszQ1AC3BE3nYmcGXfzDzALAS2\nBGYApwCnAhdWtVeSJGlYbVnvAgBSSrcDtwNERAzQ7KWU0jP9zYiICcD7gZNSSj/Op70P6IyIA1NK\nD0RECzALaE0pLc3bnAPcFhHnpZSW5/PfAByeUuoGHo6ITwIXR8S8lNIrNdtpSZJUc41yxWZzHBYR\nKyJiWURcHhHblsxrJQtpP+ibkFJ6BOgCDs4nzQBW9oWa3F1kV4gOKmnzcB5q+iwCJgJvrOneSJKk\nmhspweb7wMnA3wIfAw4FFpZc3ZkCrEkpvVC23Ip8Xl+bp0tnppTWAs+VtVnRzzooaSNJkhpUQ9yK\n2pSU0o0lX38dEQ8DvwcOAxbXpShJktRwRkSwKZdSeiwiuoG9yILNcmBsREwou2ozOZ9H/t/yUVJb\nANuWtTmgbHOTS+YNaM6cOUycOHGDaW1tbbS1lfdxliRp9Ono6KCjo2ODaT09PTXfzogMNhGxC7Ad\n8FQ+6UHgFbLRTrfkbaYBU4F78zb3ApMiYr+SfjZHAAHcX9Lm/IhoLulncyTQA/xmYzW1t7czffr0\nwe6aJEmF1N8v+0uWLKG1tbWm22mIYJM/S2YvspABsEdE7EvW/+U54AKyodvL83afB35L1rGXlNIL\nEfFV4JKIWAm8CFwK3J1SeiBvsywiFgFXRcRZwFjgy0BHPiIK4A6yAHNtRMwFdgQ+A1yWUnp5KI+B\nJEkavIYINsD+ZLeUUv75Uj7962TPtnkzWefhScCTZIHmU2VhYw6wFrgJ2Jps+PjZZdt5D3AZ2Wio\ndXnbc/tmppTWRcQxwBXAPcAq4BqyYCVJkhpcQwSb/NkzGxuh9fbNWMdLwDn5Z6A2zwOzN7GePwPH\nbGp7kiSp8YyU4d6SJEmbZLCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmF\nYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCR\nJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFYbCRJEmFsWW9C5BUTF1dXXR3d9e1hs7OzrpuX9Lw\nM9hIqrmuri6mTWuht3d1vUuRNMoYbCTVXHd3dx5qrgNa6ljJQuCTddy+pOFmsJE0hFqA6XXcvrei\npNHGzsOSJKkwDDaSJKkwDDaSJKkwDDaSJKkwDDaSJKkwDDaSJKkwDDaSJKkwDDaSJKkwDDaSJKkw\nDDaSJKkwDDaSJKkwDDaSJKkwqgo2EfHeiBhX62IkSZIGo9orNu3A8oi4MiIOrGVBkiRJ1ao22OwE\nnAbsAtwdEb+KiI9GxPa1K02SJKkyVQWblNKalNI3U0pHA1OBa4H/DTweETdHxNEREbUsVJIkaVMG\n3Xk4pfQUcBewGEjA/kAH8GhEHDLY9UuSJG2uqoNNRDRHxIcj4iHgbmAH4Djg9cDOwK3AN2pSpSRJ\n0mbYspqFIuIW4CjgMeBq4OsppWdKmrwYEfOBjwy+REmSpM1TVbABXgDellL66UbaPAPsXeX6JUmS\nKlZVsEkpnbIZbRLw+2rWL0mSVI1qH9DXHhFn9zP97Ij40uDLkiRJqly1nYdPAO7pZ/p9wN9XX44k\nSVL1qg02zWT9bMr15PMkSZKGXbXB5vfArH6mzyIbKSVJkjTsqh0VtQBYEBHbAT/Mpx0BfAw4rxaF\nSZIkVaraUVFX5W/3Ph/4dD75ceD/pJT+vVbFSZIkVaLaKzaklL4MfDkidgT+klJ6vnZlSZIkVa7q\nYNMnf1eUJElS3VX7HJvtI+JrEdEVEb0Rsab0U+siJUmSNke1V2yuAfYEvgA8RfZWb0mSpLqqNtjM\nBGamlJbWshhJkqTBqPY5No/jVRpJktRgqg02c4DPRcQutSxGkiRpMKq9FXUt8FrgTxHxAvBy6cyU\n0g6DLUySJKlS1Qabj9e0CkmSpBqo9snDX611IZIkSYNVbR8bImK3iJgXEddGxA75tCMjoqV25UmS\nJG2+ah/Qdwjwa+BQ4ERgm3xWK3BhbUqTJEmqTLVXbD4PzEspHQ6UPmn4B8CMQVclSZJUhWqDzZuB\nm/qZ/jSwfaUri4hDIuI7EfFERKyLiGP7aXNhRDwZEasj4s6I2Kts/tYR8ZWI6I6IFyPipr5bZCVt\nXhcR10dET0SsjIirI2J8WZtdI+K2iFgVEcsjYn5EVH3LTpIkDZ9qf2D3AFP6mb4v8EQV6xsP/AL4\nIP08+C8i5gIfAk4HDgRWAYsiYmxJswXA0cC7yJ6MvBPwrbJV3QC0AEfkbWcCV5ZsZwywkKxT9Qzg\nFOBUvL0mSdKIUO1w7/8ALo6Id5MHkYg4CPgScF2lK0sp3Q7cnq8n+mlyLvCZlNL38jYnAyuA44Ab\nI2IC8H7gpJTSj/M27wM6I+LAlNIDeafmWUBr36sgIuIc4LaIOC+ltDyf/wbg8JRSN/BwRHwy39d5\nKaVXKt03SZI0fKq9YvN/gT8AT5J1HP4NcA/wn8BnalNaJiJ2J7s69IO+aSmlF4D7gYPzSfuThbTS\nNo8AXSVtZgAry95vdRdZMDuopM3DeajpswiYCLyxRrskSZKGSLXPsXkJeF9EXAi8iSzcLEkpLatl\ncbkpZOFjRdn0Ffz1dthkYE0eeAZqM4WsD9B6KaW1EfFcWZv+ttM376FqdkCSJA2Pam9FAZBSegx4\nrEa1jGhz5sxh4sSJG0xra2ujra2tThVJktQ4Ojo66Ojo2GBaT09PzbdTVbCJiH/b2PyU0unVldOv\n5UCQXZUpvZoyGVha0mZsREwou2ozOZ/X16Z8lNQWwLZlbQ4o2/7kknkDam9vZ/r06ZvcGUmSRqP+\nftlfsmQJra2tNd1OtX1sdiz7TAXeQfawvv5GS1Utvyq0nGwkEwB5Z+GDyPr1ADwIvFLWZlpe1735\npHuBSRGxX8nqjyALTfeXtHlTRDSXtDmSbBTYb2q0S5IkaYhU28fmneXTImJL4F+pIgDkz5LZiyxk\nAOwREfsCz6WU/kw2lPsTEfE74I9kHZQfB76d1/NCRHwVuCQiVgIvApcCd6eUHsjbLIuIRcBVEXEW\nMBb4MtCRj4gCuCOv/9p8iPmO+bYuSylt8AZzSZLUeAbVx6ZUSumViPgC8CPgkgoX3x9YTNZJOJEN\nGwf4OvD+lNL8iGgie+bMJOCnwDtSSqVPPZ4DrCV7cODWZMPHzy7bznuAy8hGQ63L255bsg/rIuIY\n4Aqyq0GrgGuACyrcH0mSVAc1Cza53YGtKl0of/bMRm+LpZTmAfM2Mv8l4Jz8M1Cb54HZm9jOn4Fj\nNtZGkiQ1pmo7D88vn0R22+ZYqnhAnyRJUi1Ue8Xm4LLv64BngI8DVw2qIkmSpCpV23n4kFoXIkmS\nNFi+tVqSJBVGtX1s/pN+3sLdn5TSgdVsQ5IkqVLV9rFZDJwB/Ja/PgBvBjCNbEj2S4MvTZIkqTLV\nBptJwFdSSueXToyIi4DJKaUPDLoySZKkClXbx+ZE4Gv9TL8GOKHqaiRJkgah2mDzEtmtp3Iz8DaU\nJEmqk2pvRV0KXJm/UPKBfNpBwGnA52pRmCRJUqWqfY7NRRHxGNl7lvr603QCp6eUbqhVcZIkSZWo\n+l1ReYAxxEiSpIZR9QP6ImJCRJwaERdGxOvyaftGxI61K0+SJGnzVfuAvr8B7gJWA7uSjYZaCfw9\nsDNwSo3qkyRJ2mzVXrFpJ7sNtSfQWzL9NmDmYIuSJEmqRrXB5gDg8pRS+WsVngC8FSVJkuqi2mDz\nMrBNP9P3ArqrL0eSJKl61Qab7wKfjIi+PjopInYGLgZurkllkiRJFao22HwU2BZYDrwG+CHwB7L+\nNudvZDlJkqQhU+0D+lYCh0fEocC+ZLellgCL+ul3I0mSNCwqDjYRsRXwPeBDKaUfAz+ueVWSJElV\nqPhWVErpZaAV8MqMJElqKNX2sbkeeF8tC5EkSRqsat8VlYAPRcTbgJ8DqzaYmdLHBluYJElSpaoN\nNq3AL/M/v7lsnreoJElSXVQUbCJiD+CxlNIhQ1SPJElS1SrtY/MosH3fl4j4j4iYXNuSJEmSqlNp\nsImy70cB42tUiyRJ0qBUOypKkiSp4VQabBKv7hxsZ2FJktQQKh0VFcA1EfFS/n0c8K8RUT7c+/ha\nFCdJklSJSoPN18u+X1erQiRJkgaromCTUvJpw5IkqWHZeViSJBWGwUaSJBWGwUaSJBWGwUaSJBWG\nwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaS\nJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWG\nwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaSJBWGwUaS\nJBWGwUaSJBXGiAg2EXFBRKwr+/ymrM2FEfFkRKyOiDsjYq+y+VtHxFciojsiXoyImyJih7I2r4uI\n6yOiJyJWRsTVETF+OPZRkiQN3ogINrlfAZOBKfnnf/TNiIi5wIeA04EDgVXAoogYW7L8AuBo4F3A\nTGAn4Ftl27gBaAGOyNvOBK4cgn2RJElDYMt6F1CBV1JKzwww71zgMyml7wFExMnACuA44MaImAC8\nHzgppfTjvM37gM6IODCl9EBEtACzgNaU0tK8zTnAbRFxXkpp+ZDunSRJGrSRdMVm74h4IiJ+HxHX\nRcSuABGxO9kVnB/0NUwpvQDcDxycT9qfLMSVtnkE6CppMwNY2RdqcncBCThoaHZJkiTV0kgJNvcB\np5JdUTkT2B34Sd7/ZQpZ+FhRtsyKfB5kt7DW5IFnoDZTgKdLZ6aU1gLPlbSRJEkNbETcikopLSr5\n+quIeAD4E3AisKw+VW1ozpw5TJw4cYNpbW1ttLW11akiSZIaR0dHBx0dHRtM6+npqfl2RkSwKZdS\n6omI3wJ7AT8CguyqTOlVm8lA322l5cDYiJhQdtVmcj6vr035KKktgG1L2gyovb2d6dOnV74zkiSN\nAv39sr9kyRJaW1trup2RcitqAxGxDVmoeTKl9BhZ8DiiZP4Esn4x9+STHgReKWszDZgK3JtPuheY\nFBH7lWzqCLLQdP/Q7IkkSaqlEXHFJiK+AHyX7PbTzsCngZeB/5c3WQB8IiJ+B/wR+AzwOPBtyDoT\nR8RXgUsiYiXwInApcHdK6YG8zbKIWARcFRFnAWOBLwMdjoiSJGlkGBHBBtiF7Bkz2wHPAD8DZqSU\nngVIKc2PiCayZ85MAn4KvCOltKZkHXOAtcBNwNbA7cDZZdt5D3AZ2WiodXnbc4donyRJUo2NiGCT\nUtpkD9yU0jxg3kbmvwSck38GavM8MLvyCiVJUiMYkX1sJEmS+mOwkSRJhWGwkSRJhWGwkSRJhWGw\nkSRJhWGwkSRJhWGwkSRJhWGwkSRJhWGwkSRJhWGwkSRJhWGwkSRJhWGwkSRJhWGwkSRJhWGwkSRJ\nhWGwkSRJhbFlvQuQVFtdXV10d3fXtYbOzs66bl/S6GWwkQqkq6uLadNa6O1dXe9S1I9GCXzNzc1M\nnTq13mVIQ8JgIxVId3d3HmquA1rqWMlC4JN13H6jeQoYw+zZs+tdCADjxjXxyCOdhhsVksFGKqQW\nYHodt98YVyYax/PAOuofOAE66e2dTXd3t8FGhWSwkaRhU+/AKRWfo6IkSVJhGGwkSVJhGGwkSVJh\nGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwk\nSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJh\nGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwk\nSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJhGGwkSVJh\nGGwkSVJhGGwkSVJhbFnvAqSi6Orqoru7u641dHZ21nX7klRvBhupBrq6upg2rYXe3tX1LkXaLI0Q\ngpubm5k6dWq9y1DBGGxUFx0dHbS1tdW7jJrp7u7OQ811QMsQbul24O0bmb8Q+OQQbl8j31PAGGbP\nnl3vQhg3rolHHuksTLgp2r9rI5XBph8RcTZwHjAFeAg4J6X0n/WtqliK+w9ACzB9CNc/Dzh/I/Pr\n/1u4Gt3zwDo2HcLnAO1DWEcnvb2z6e7uNtiopgw2ZSLi74EvAacDD5D97V4UEfuklOrbgaKB/OM/\nfpwrrvjXqpfv7V3FNttMGnQdEdDe/kU+8IEPDHpd0uiyqRA+cRPzi6NW/eN6enpYsmRJ1ct7a642\nDDavNge4MqX0DYCIOBM4Gng/ML+ehTWS7353IatW/Q3wv6pcw7+zatX7a1DJv7Fo0SKDjaSq1Lp/\nXGtra9XLFu3WXL0YbEpExFZAK/DZvmkppRQRdwEH162whjUd+GiVy/54EMv+VcSdrF69elC/JdVC\nI3TElEaiev/d6ezsrGH/uMHcviverbl6MdhsqBnYAlhRNn0FMG2AZcZB/f9yDrfe3r8AvwL+rco1\n/GkQy/5VSr/n+9//IwsXLhz0umpjIUPbz+Vx4PqNzL97mOrYFOtozDpg82vZ1Lk2WEuBaIhOzJnH\narCOF6n+/2+2/dH2s6Rkf8fVap2RUqrVuka8iNgReAI4OKV0f8n0zwMzU0qvumoTEe9haP/2S5JU\ndP+QUrqhFivyis2GuoG1wOSy6ZOB5QMsswj4B+CPQO+QVSZJUvGMA3Yj+1laE16xKRMR9wH3p5TO\nzb8H0AXnvmbQAAAFVElEQVRcmlL6Ql2LkyRJG+UVm1e7BLgmIh7kr8O9m4Br6lmUJEnaNINNmZTS\njRHRDFxIdgvqF8CslNIz9a1MkiRtireiJElSYYypdwGSJEm1YrCRJEmFYbCpUEScHxF3R8SqiHhu\nM5f5WkSsK/s0yhPlhkU1xy1f7sKIeDIiVkfEnRGx11DW2Ugi4nURcX1E9ETEyoi4OiLGb2KZUXeu\nRcTZEfFYRPwlIu6LiAM20f6wiHgwInoj4rcRccpw1dpIKjluEXFoP+fV2ojYYThrrqeIOCQivhMR\nT+T7f+xmLDOqz7VKj1mtzjODTeW2Am4Erqhwue+TdUaekn9G2ytgKz5uETEX+BDZC0kPBFaRvZB0\n7JBU2HhuIHvG+xFk7yubCVy5GcuNmnOt5KW1FwD7AQ+RnSPNA7TfDfge8ANgX+BfgKsj4n8OR72N\notLjlkvA3vz1vNoxpfT0UNfaQMaTDSb5INmx2CjPNaDCY5Yb/HmWUvJTxQc4BXhuM9t+Dbi53jU3\nwqfC4/YkMKfk+wTgL8CJ9d6PYThObwDWAfuVTJsFvAJM2chyo+pcA+4D/qXke5C9C+BjA7T/PPDL\nsmkdwMJ670uDH7dDyR5eOqHetTfCJ/+7eewm2niuVX7ManKeecVm+BwWESsiYllEXB4R29a7oEYW\nEbuTpfUf9E1LKb0A3M/oeCHpwcDKlNLSkml3kf02c9Amlh0V51rJS2tLz5FEdpwGOkdm5PNLLdpI\n+8Kp8rhBFn5+kd8aviMi/vvQVjrijfpzrUqDPs8MNsPj+8DJwN8CHyNLpQvzpxqrf1PIfoj390LS\nKcNfzrCbAmxw+TWltBZ4jo3v/2g61zb20tqBjtGUAdpPiIita1tew6rmuD0FnAG8Czge+DPwo4h4\ny1AVWQCea5WryXnmA/qAiPgcMHcjTRLQklL6bTXrTyndWPL11xHxMPB74DBgcTXrbARDfdyKaHOP\nWbXrL+q5pvrK/w6X/j2+LyL2JHsy+6jqEKuhU6vzzGCT+SJZ34SN+UOtNpZSeiwiuoG9GNk/bIby\nuC0nuyQ5mQ1/65kMLO13iZFhc4/ZcmCDkQARsQWwLQO/kPVVCnSu9aeal9YuH6D9Cymll2pbXsOq\n5rj15wHgrbUqqoA812qj4vPMYAOklJ4Fnh2u7UXELsB2ZJfdRqyhPG75D+TlZCOCfgkQERPI+pd8\nZSi2ORw295hFxL3ApIjYr6SfzRFkYe/+zd1eUc61/qSUXs7f6XYE8B1Y/9LaI4BLB1jsXuAdZdOO\nzKePClUet/68hQKeVzU06s+1Gqn8PKt3T+mR9gF2JRu69ymgJ//zvsD4kjbLgL/L/zwemE/2A/n1\nZP94/BzoBLaq9/406nHLv3+MLAS8E3gTcCvwKDC23vszTMdsYX6uHED2G8sjwLVlbUb1uQacCKwm\n61f0BrLh8M8C2+fzPwd8vaT9bsCLZCNWppENQ10DvK3e+9Lgx+1c4FhgT+CNwALgZeCweu/LMB6z\n8fm/WW8hG+Hz4fz7rp5rNTtmNTnP6r7jI+1DdhthbT+fmSVt1gIn538eB9xOdlmyl+w2wxV9/4CM\nlk+lx61k2jyyYd+ryUYU7FXvfRnGYzYJuI4sCK4ErgKaytqM+nMt/4HxR7JHAdwL7F923v2wrP1M\n4MG8/aPAe+u9D41+3IB/zI/VKuAZshFVM4e75jofr0PzH87l/4b9u+dabY5Zrc4zX4IpSZIKw+He\nkiSpMAw2kiSpMAw2kiSpMAw2kiSpMAw2kiSpMAw2kiSpMAw2kiSpMAw2kiSpMAw2kiSpMAw2kiSp\nMAw2kiSpMP4/AybhREKqI7sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6540702b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_data.plot.hist('steer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0566038\n"
     ]
    }
   ],
   "source": [
    "row = X_train_data.iloc[[2]]\n",
    "print(row['steer'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, most of our steering angles are around zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Brightness Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal and Vertical Shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_int = np.random.choice(len(X_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_int:  14568\n",
      "impath  /home/jj/Documents/Behavioral_Cloning/data/IMG/left_2016_12_01_13_46_24_618.jpg\n",
      "steer:  0.162699\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_image_from_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7514e9b98361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steer: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steer: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_image_from_path' is not defined"
     ]
    }
   ],
   "source": [
    "print('rand_int: ', rand_int)\n",
    "row = X_train_data.iloc[[rand_int]]\n",
    "impath = row['image'].values[0]\n",
    "steer = row['steer'].values[0]\n",
    "print('impath ', impath)\n",
    "print('steer: ', steer)\n",
    "\n",
    "img, ang = preprocess_image_from_path(impath, steer)\n",
    "plt.imshow(img)\n",
    "print('steer: ', ang)\n",
    "\n",
    "# img = mpimg.imread(impath)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess image, \n",
    "    input: image (original shape)\n",
    "    output: image (shape is (200, 66, 3) )\n",
    "    \"\"\"\n",
    "    # crop shape\n",
    "    image = image[55:image.shape[0] - 24,:,:]\n",
    "    # resize to (66, 200)\n",
    "    img = cv2.resize(image, (200, 66), interpolation=cv2.INTER_AREA)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_valid_from_path(image_path, steering_angle):\n",
    "    img = mpimg.imread(image_path)\n",
    "    img = preprocess_image(img)\n",
    "    return img, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_from_path(image_path, steering_angle):\n",
    "    img = mpimg.imread(image_path)\n",
    "    img = preprocess_image(img)\n",
    "    return img, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_training_data(data, batch_size = 32):\n",
    "    \"\"\"\n",
    "    We create a loop through out data and \n",
    "    send out an individual row in the dataframe to preprocess_image_from_path, \n",
    "    which is then sent to preprocess_image\n",
    "    inputs: \n",
    "    data: pandas DataFrame\n",
    "    batch_size: batch sizes, size to make each batch\n",
    "    returns a yield (image_batch, label_batch)\n",
    "    \"\"\"\n",
    "    image_batch = np.zeros((batch_size, 66, 200, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            idx = np.random.randint(len(data))\n",
    "            row = data.iloc[[idx]].reset_index()\n",
    "            x, y = preprocess_image_from_path(row['image'].values[0], row['steer'].values[0])\n",
    "    \n",
    "            image_batch[i] = x\n",
    "            label_batch[i] = y\n",
    "        yield (image_batch, label_batch)\n",
    "    \n",
    "def generate_validation_data(data):\n",
    "    while True:\n",
    "        for idx in range(len(data)):\n",
    "            row = data.iloc[[idx]].reset_index()\n",
    "            img, angle = preprocess_image_valid_from_path(row['image'].values[0], row['steer'].values[0])\n",
    "            img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "            angle = np.array([[angle]])\n",
    "            yield img, angle\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I chose to use Nvidia's network architecture. Input (200 x 66 sized image) output (1 steering angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "\n",
    "N_img_height = 66\n",
    "N_img_width = 200\n",
    "N_img_channels = 3\n",
    "def nvidia_model():\n",
    "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalization\n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1, input_shape = inputShape))\n",
    "    # cropping 70 off top 25 off bottom\n",
    "    # model.add(Cropping2D(cropping=((70,25), (0, 0)))) Probably going to do cropping in my process\n",
    "\n",
    "    # subsample is strides\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2,2),  activation='relu'))\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2,2),  activation='relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  10074\n",
      "len train : 40296\n"
     ]
    }
   ],
   "source": [
    "print('len: ', len(X_valid_data))\n",
    "print('len train :', len(X_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_size = len(X_valid_data)\n",
    "valid_generator = generate_validation_data(X_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "20480/20480 [==============================] - 95s - loss: 0.0456 - acc: 0.1118 - val_loss: 0.0426 - val_acc: 0.1143\n",
      "Epoch 2/8\n",
      "20480/20480 [==============================] - 86s - loss: 0.0436 - acc: 0.1156 - val_loss: 0.0423 - val_acc: 0.1143\n",
      "Epoch 3/8\n",
      "20480/20480 [==============================] - 88s - loss: 0.0438 - acc: 0.1181 - val_loss: 0.0424 - val_acc: 0.1143\n",
      "Epoch 4/8\n",
      "20480/20480 [==============================] - 84s - loss: 0.0441 - acc: 0.1093 - val_loss: 0.0413 - val_acc: 0.1143\n",
      "Epoch 5/8\n",
      "20480/20480 [==============================] - 86s - loss: 0.0438 - acc: 0.1157 - val_loss: 0.0420 - val_acc: 0.1143\n",
      "Epoch 6/8\n",
      "20480/20480 [==============================] - 84s - loss: 0.0426 - acc: 0.1204 - val_loss: 0.0418 - val_acc: 0.1143\n",
      "Epoch 7/8\n",
      "20480/20480 [==============================] - 85s - loss: 0.0430 - acc: 0.1195 - val_loss: 0.0413 - val_acc: 0.1143\n",
      "Epoch 8/8\n",
      "20480/20480 [==============================] - 84s - loss: 0.0446 - acc: 0.1161 - val_loss: 0.0412 - val_acc: 0.1144\n",
      "<keras.callbacks.History object at 0x7ff5e403c6a0>\n"
     ]
    }
   ],
   "source": [
    "train_generator = generate_training_data(X_train_data, 256)\n",
    "model = nvidia_model()\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        samples_per_epoch = 20480, \n",
    "        nb_epoch = 8,\n",
    "        validation_data = valid_generator,\n",
    "        nb_val_samples = val_size)\n",
    "print(history)\n",
    "    \n",
    "model.save_weights('model-weights1.h5')\n",
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 66, 200, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 98, 24)    1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 47, 36)    21636       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 22, 48)     43248       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 20, 64)     27712       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 18, 64)     36928       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1152)          0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           115300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 252219\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('yo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
