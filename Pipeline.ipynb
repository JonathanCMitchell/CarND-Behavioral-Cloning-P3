{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Annie data\n",
    "\n",
    "with open('training_data_annieonly.p', 'rb') as handle:\n",
    "    training_data_annie = pickle.load(handle)\n",
    "    df_annie = pd.DataFrame.from_dict(training_data_annie)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_data, X_valid_data = train_test_split(df, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_data_recovery, X_valid_data_recovery = train_test_split(df_annie, test_size = 0.2)\n",
    "print('X_train_data_recovery shape: ', X_train_data_recovery.shape)\n",
    "print('X_valid_data_recovery shape: ', X_valid_data_recovery.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_data_recovery.plot.hist('steer', bins=100,range=(-1,1),facecolor=\"r\", histtype = 'step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New =========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(10)\n",
    "print(len(df))\n",
    "print(len(X_train_data))\n",
    "print(len(X_valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View histogram of steering angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_data.plot.hist('steer', bins=100,range=(-1,1),facecolor=\"r\", histtype = 'step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row = X_train_data.iloc[[2]]\n",
    "print(row['steer'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, most of our steering angles are around zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_int = np.random.choice(len(X_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('rand_int: ', rand_int)\n",
    "row = X_train_data.iloc[[rand_int]]\n",
    "impath = row['image'].values[0]\n",
    "steer = row['steer'].values[0]\n",
    "print('impath ', impath)\n",
    "print('steer: ', steer)\n",
    "\n",
    "img, ang = preprocess_image_from_path(impath, steer)\n",
    "plt.imshow(img)\n",
    "print('steer: ', ang)\n",
    "\n",
    "# img = mpimg.imread(impath)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('rand_int: ', rand_int)\n",
    "row = X_train_data.iloc[[rand_int]]\n",
    "impath = row['image'].values[0]\n",
    "steer = row['steer'].values[0]\n",
    "print('impath ', impath)\n",
    "print('steer: ', steer)\n",
    "\n",
    "img, ang = preprocess_image_from_path(impath, steer)\n",
    "plt.imshow(img)\n",
    "print('steer: ', ang)\n",
    "\n",
    "# img = mpimg.imread(impath)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brightness Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal and Vertical Shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_image(image):\n",
    "    image_flipped = np.fliplr(image)\n",
    "    return image_flipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess image, \n",
    "    input: image (original shape)\n",
    "    output: image (shape is (220, 66, 3) )\n",
    "    \"\"\"    \n",
    "    # crop shape\n",
    "    image = image[image.shape[0] * 0.34:image.shape[0] * 0.875,:,:]\n",
    "    # resize to (66, 220)\n",
    "    img = cv2.resize(image, (220, 66), interpolation=cv2.INTER_AREA)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_valid_from_path(image_path, steering_angle):\n",
    "    img = mpimg.imread(image_path)\n",
    "    img = preprocess_image(img)\n",
    "    return img, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_from_path(image_path, steering_angle):\n",
    "    img = mpimg.imread(image_path)\n",
    "    \n",
    "    # chance to flip\n",
    "#     prob_flip = np.random.randint(2)\n",
    "#     if prob_flip == 1:\n",
    "#         img = flip_image(img)\n",
    "#         steering_angle = -1 * steering_angle\n",
    "        \n",
    "    img = preprocess_image(img)\n",
    "    return img, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I created two generators, one for training data and one for validation data. In the training generator we create batches of 32 for each training sample. Therefore if I have `samples_per_epoch = 10` that means for each of those samples I yield 32 images from the training generator. I did this because it allows me to have control over what the batches turn out to be. In this case [ADD HERE]```add here I will add a probability function to pass a certain image path to the processor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_training_data_old(data, batch_size = 32):\n",
    "    \"\"\"\n",
    "    We create a loop through out data and \n",
    "    send out an individual row in the dataframe to preprocess_image_from_path, \n",
    "    which is then sent to preprocess_image\n",
    "    inputs: \n",
    "    data: pandas DataFrame\n",
    "    batch_size: batch sizes, size to make each batch\n",
    "    returns a yield (image_batch, label_batch)\n",
    "    \"\"\"\n",
    "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            idx = np.random.randint(len(data))\n",
    "            row = data.iloc[[idx]].reset_index()\n",
    "            x, y = preprocess_image_from_path(row['image'].values[0], row['steer'].values[0])\n",
    "            \n",
    "            image_batch[i] = x\n",
    "            label_batch[i] = y\n",
    "        yield shuffle(image_batch, label_batch)\n",
    "    \n",
    "def generate_validation_data(data):\n",
    "    while True:\n",
    "        for idx in range(len(data)):\n",
    "            row = data.iloc[[idx]].reset_index()\n",
    "            img, angle = preprocess_image_valid_from_path(row['image'].values[0], row['steer'].values[0])\n",
    "            img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "            angle = np.array([[angle]])\n",
    "            yield img, angle\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_training_data(data, batch_size = 32):\n",
    "    \"\"\"\n",
    "    We create a loop through out data and \n",
    "    send out an individual row in the dataframe to preprocess_image_from_path, \n",
    "    which is then sent to preprocess_image\n",
    "    inputs: \n",
    "    data: pandas DataFrame\n",
    "    batch_size: batch sizes, size to make each batch\n",
    "    returns a yield (image_batch, label_batch)\n",
    "    \"\"\"\n",
    "    image_batch = np.zeros((batch_size*2, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size*2))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            idx = np.random.randint(len(data))\n",
    "            row = data.iloc[[idx]].reset_index()\n",
    "            x, y = preprocess_image_from_path(row['image'].values[0], row['steer'].values[0])\n",
    "            \n",
    "            # flip an image and return it\n",
    "            x2 = np.fliplr(x)\n",
    "            y2 = -1 * y\n",
    "            \n",
    "            image_batch[i] = x\n",
    "            label_batch[i] = y\n",
    "            image_batch[i+1] = x2\n",
    "            image_batch[i+2] = y2\n",
    "        yield shuffle(image_batch, label_batch)\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_validation_data(data):\n",
    "    while True:\n",
    "        for idx in range(len(data)):\n",
    "            row = data.iloc[[idx]].reset_index()\n",
    "            img, angle = preprocess_image_valid_from_path(row['image'].values[0], row['steer'].values[0])\n",
    "            img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "            angle = np.array([[angle]])\n",
    "            yield img, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I chose to use Nvidia's network architecture. Input (220 x 66 sized image) output (1 steering angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use the Nvidia model architecture which can be found [here add link]\n",
    "I used ELu's because they push mean unit activation functions closer to zero [https://arxiv.org/pdf/1511.07289v1.pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "\n",
    "N_img_height = 66\n",
    "N_img_width = 220\n",
    "N_img_channels = 3\n",
    "def nvidia_model():\n",
    "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalization\n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1, input_shape = (66, 220, 3)))\n",
    "    # cropping 70 off top 25 off bottom\n",
    "    # model.add(Cropping2D(cropping=((70,25), (0, 0)))) Probably going to do cropping in my process\n",
    "\n",
    "    # subsample is strides\n",
    "    model.add(Convolution2D(24, 5, 5, \n",
    "                            subsample=(2,2), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv1'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(36, 5, 5, \n",
    "                            subsample=(2,2), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv2'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(48, 5, 5, \n",
    "                            subsample=(2,2), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, 3, 3, \n",
    "                            subsample = (1,1), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal', #gaussian init\n",
    "                            name = 'conv4'))\n",
    "    \n",
    "    model.add(ELU())              \n",
    "    model.add(Convolution2D(64, 3, 3, \n",
    "                            subsample= (1,1), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv5'))\n",
    "              \n",
    "              \n",
    "    model.add(Flatten(name = 'flatten'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100, init = 'he_normal', name = 'fc1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, init = 'he_normal', name = 'fc2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, init = 'he_normal', name = 'fc3'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    # do not put activation at the end because we want to exact output, not a class identifier\n",
    "    model.add(Dense(1, name = 'output', init = 'he_normal'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('len: ', len(X_valid_data))\n",
    "print('len train :', len(X_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_size = len(X_valid_data)\n",
    "valid_generator = generate_validation_data(X_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "for i in range(3):\n",
    "    train_generator = generate_training_data(X_train_data, 256)\n",
    "    history = model.fit_generator(\n",
    "            train_generator, \n",
    "            samples_per_epoch = 20480, # try putting the whole thing in here in the future\n",
    "            nb_epoch = 6,\n",
    "            validation_data = valid_generator,\n",
    "            nb_val_samples = val_size)\n",
    "    print(history)\n",
    "    \n",
    "    model.save_weights('model-weightsU3.h5')\n",
    "    model.save('modelU3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out sequential running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this one\n",
    "model = nvidia_model()\n",
    "for i in range(3):\n",
    "    train_generator = generate_training_data(X_train_data, 256)\n",
    "    history = model.fit_generator(\n",
    "            train_generator, \n",
    "            samples_per_epoch = 20480, # try putting the whole thing in here in the future\n",
    "            nb_epoch = 6,\n",
    "            validation_data = valid_generator,\n",
    "            nb_val_samples = val_size)\n",
    "    print(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_recovery_generator = generate_training_data(X_train_data_recovery, 16)\n",
    "history = model.fit_generator(train_recovery_generator, \n",
    "            samples_per_epoch = len(X_train_data_recovery), # try putting the whole thing in here in the future\n",
    "            nb_epoch = 8,\n",
    "            validation_data = valid_generator,\n",
    "            nb_val_samples = val_size)\n",
    "\n",
    "model.save_weights('model-weightsU5.h5')\n",
    "model.save('modelU5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "for i in range(3):\n",
    "    train_generator = generate_training_data(X_train_data_recovery, 256)\n",
    "    history = model.fit_generator(\n",
    "            train_generator, \n",
    "            samples_per_epoch = 20480, # try putting the whole thing in here in the future\n",
    "            nb_epoch = 6,\n",
    "            validation_data = valid_generator,\n",
    "            nb_val_samples = val_size)\n",
    "    print(history)\n",
    "    \n",
    "    model.save_weights('model-weightsU3.h5')\n",
    "    model.save('modelU3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('yo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
