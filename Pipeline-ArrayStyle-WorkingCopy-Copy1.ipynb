{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataFrame(data_path):\n",
    "    \"\"\"\n",
    "    input: data_path: path to data\n",
    "    return: data frame\n",
    "    \"\"\"\n",
    "    data_frame = pd.read_csv(data_path)\n",
    "    data_frame.columns = ['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into left turns, right turns, center (no turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createTrainingDataPathsCLR(df, prefix_path):\n",
    "    \"\"\"\n",
    "    creates training data and training labels/ measurements from a data frame\n",
    "    inputs:\n",
    "    df: pandas DataFrame object\n",
    "    start: starting row to grab data\n",
    "    end: ending row to grab data\n",
    "    correction_factor: factor to correct steering angles\n",
    "    \"\"\"    \n",
    "    # Turn types\n",
    "    center_turns = []\n",
    "    left_turns = []\n",
    "    right_turns = []\n",
    "    \n",
    "    \n",
    "    abs_path_to_IMG = os.path.abspath(prefix_path)\n",
    "    for idx, row in df.iterrows():\n",
    "        center_image_cam = os.path.join(abs_path_to_IMG, row['center'].strip())\n",
    "        left_image_cam = os.path.join(abs_path_to_IMG, row['left'].strip())\n",
    "        right_image_cam = os.path.join(abs_path_to_IMG, row['right'].strip())\n",
    "        steering_angle = row['steering']\n",
    "        \n",
    "        # Right image condition\n",
    "        if steering_angle > 0.125:\n",
    "            right_turns.append([center_image_cam, left_image_cam, right_image_cam, steering_angle])\n",
    "            \n",
    "        # This is a left image\n",
    "        elif steering_angle < -1 * 0.125:\n",
    "            left_turns.append([center_image_cam, left_image_cam, right_image_cam, steering_angle])\n",
    "            \n",
    "        # This is a center image\n",
    "        else:\n",
    "        # center images\n",
    "            center_turns.append([center_image_cam, left_image_cam, right_image_cam, steering_angle])\n",
    "        \n",
    "    return (center_turns, left_turns, right_turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeMore(dataArray, amount):\n",
    "    for i in range(len(dataArray)):\n",
    "        for j in range(amount):                                    \n",
    "            dataArray.append([dataArray[i][0], dataArray[i][1], dataArray[i][2], dataArray[i][3]])\n",
    "    return dataArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from udacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pd_udacity = createDataFrame('data/driving_log.csv')\n",
    "columns = ['center', 'left', 'right', 'steering']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create centers_turns, left_turns, right_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(center_turns_udacity,\n",
    "left_turns_udacity,\n",
    "right_turns_udacity) = createTrainingDataPathsCLR(data_pd_udacity, 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make more copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "center_turns_udacity = makeMore(center_turns_udacity, 5)\n",
    "left_turns_udacity = makeMore(left_turns_udacity, 18)\n",
    "right_turns_udacity = makeMore(right_turns_udacity, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_center_udacity.index:  36714\n",
      "df_left_udacity.index:  16131\n",
      "df_right_udacity.index:  13884\n"
     ]
    }
   ],
   "source": [
    "df_center_udacity = pd.DataFrame(center_turns_udacity, columns = columns)\n",
    "df_left_udacity = pd.DataFrame(left_turns_udacity, columns = columns)\n",
    "df_right_udacity = pd.DataFrame(right_turns_udacity, columns = columns)\n",
    "\n",
    "print('df_center_udacity.index: ', len(df_center_udacity.index))\n",
    "print('df_left_udacity.index: ', len(df_left_udacity.index))\n",
    "print('df_right_udacity.index: ', len(df_right_udacity.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(np.asarray(df_center_udacity['steering'], dtype=np.float32))\n",
    "# plt.hist(np.asarray(df_center_udacity['steering'], dtype=np.float32),bins=100,range=(-0.2,0.2),facecolor=\"r\", histtype = 'step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(np.asarray(df_left_udacity['steering'], dtype=np.float32))\n",
    "# plt.hist(np.asarray(df_left_udacity['steering'], dtype=np.float32),bins=100,range=(-0.6,0.15),facecolor=\"r\", histtype = 'step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(np.asarray(df_right_udacity['steering'], dtype=np.float32))\n",
    "# plt.hist(np.asarray(df_right_udacity['steering'], dtype=np.float32),bins=100,range=(0.15,0.6),facecolor=\"r\", histtype = 'step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_center_udacity = shuffle(df_center_udacity)\n",
    "df_left_udacity = shuffle(df_left_udacity)\n",
    "df_right_udacity = shuffle(df_right_udacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames_to_concat_udacity = [df_center_udacity, df_left_udacity, df_right_udacity]\n",
    "df_udacity = pd.concat(frames_to_concat_udacity, axis = 0, join = 'outer', ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pd_recovery = createDataFrame('annie_recovery/driving_log_recovery.csv')\n",
    "columns = ['center', 'left', 'right', 'steering']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create centers_turns, left_turns, right_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(center_turns_recovery,\n",
    "left_turns_recovery,\n",
    "right_turns_recovery) = createTrainingDataPathsCLR(data_pd_recovery, 'annie_recovery/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make more copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center_turns_recovery = makeMore(center_turns_recovery, 5)\n",
    "left_turns_recovery = makeMore(left_turns_recovery, 18)\n",
    "right_turns_recovery = makeMore(right_turns_recovery, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_center_recovery = pd.DataFrame(center_turns_recovery, columns = columns)\n",
    "df_left_recovery = pd.DataFrame(left_turns_recovery, columns = columns)\n",
    "df_right_recovery= pd.DataFrame(right_turns_recovery, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_center_recovery.index:  4308\n",
      "df_center_recovery.index:  6213\n",
      "df_center_recovery.index:  3926\n"
     ]
    }
   ],
   "source": [
    "print('df_center_recovery.index: ', len(df_center_recovery.index))\n",
    "print('df_center_recovery.index: ', len(df_left_recovery.index))\n",
    "print('df_center_recovery.index: ', len(df_right_recovery.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(np.asarray(df_center_recovery['steering'], dtype=np.float32))\n",
    "# plt.hist(np.asarray(df_center_recovery['steering'], dtype=np.float32),bins=100,range=(-0.2,0.2),facecolor=\"r\", histtype = 'step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(np.asarray(df_left_recovery['steering'], dtype=np.float32))\n",
    "# plt.hist(np.asarray(df_left_recovery['steering'], dtype=np.float32),bins=100,range=(-0.2,0.2),facecolor=\"r\", histtype = 'step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(np.asarray(df_right_recovery['steering'], dtype=np.float32))\n",
    "# plt.hist(np.asarray(df_right_recovery['steering'], dtype=np.float32),bins=100,range=(-0.2,0.2),facecolor=\"r\", histtype = 'step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_center_recovery = shuffle(df_center_recovery)\n",
    "df_left_recovery = shuffle(df_left_recovery)\n",
    "df_right_recovery = shuffle(df_right_recovery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames_to_concat_recovery = [df_center_recovery, df_left_recovery, df_right_recovery]\n",
    "df_recovery = pd.concat(frames_to_concat_recovery, axis = 0, join = 'outer', ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat both dataframes together (Udacity + Recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = [df_udacity, df_recovery]\n",
    "train_data = pd.concat(frames, axis = 0, join = 'outer', ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data size:  81176\n"
     ]
    }
   ],
   "source": [
    "print('train_data size: ', len(train_data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_image_from_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-35ebd4cbd40a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'steering'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mrandom_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_image_from_path' is not defined"
     ]
    }
   ],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_from_path(row['center'].values[0], row['steering'].values[0])\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'ang: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = shuffle(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data size:  64940\n",
      "valid_data size:  16236\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = train_test_split(train_data, test_size = 0.2)\n",
    "print('train_data size: ', len(train_data.index))\n",
    "print('valid_data size: ', len(valid_data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of steering angles training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.32300000e+03,   4.50000000e+01,   3.20000000e+01,\n",
       "          3.20000000e+01,   6.20000000e+01,   0.00000000e+00,\n",
       "          4.60000000e+01,   1.70000000e+01,   4.80000000e+01,\n",
       "          8.70000000e+01,   4.60000000e+01,   6.00000000e+01,\n",
       "          4.50000000e+01,   4.70000000e+01,   9.20000000e+01,\n",
       "          8.80000000e+01,   1.15000000e+02,   1.08000000e+02,\n",
       "          6.20000000e+01,   7.10000000e+01,   4.90000000e+01,\n",
       "          1.50000000e+01,   7.30000000e+01,   1.09000000e+02,\n",
       "          1.78000000e+02,   2.33000000e+02,   1.11000000e+02,\n",
       "          3.92000000e+02,   3.29000000e+02,   4.38000000e+02,\n",
       "          4.51000000e+02,   2.89000000e+02,   3.00000000e+02,\n",
       "          3.27000000e+02,   4.99000000e+02,   1.44700000e+03,\n",
       "          8.47000000e+02,   6.32000000e+02,   1.34100000e+03,\n",
       "          1.13600000e+03,   4.75000000e+02,   9.54000000e+02,\n",
       "          3.57500000e+03,   1.25900000e+03,   4.72000000e+02,\n",
       "          5.32000000e+02,   1.34100000e+03,   1.29800000e+03,\n",
       "          4.39000000e+02,   5.78000000e+02,   2.44550000e+04,\n",
       "          4.48000000e+02,   9.57000000e+02,   8.21000000e+02,\n",
       "          9.43000000e+02,   5.44000000e+02,   1.43500000e+03,\n",
       "          1.10500000e+03,   3.94300000e+03,   7.73000000e+02,\n",
       "          4.55000000e+02,   2.67000000e+02,   3.18000000e+02,\n",
       "          7.37000000e+02,   2.92000000e+02,   6.93000000e+02,\n",
       "          2.69000000e+02,   7.38000000e+02,   4.35000000e+02,\n",
       "          1.34000000e+02,   1.53000000e+02,   8.30000000e+01,\n",
       "          1.42000000e+02,   2.17000000e+02,   1.63000000e+02,\n",
       "          9.00000000e+01,   3.40000000e+01,   4.00000000e+01,\n",
       "          8.30000000e+01,   7.50000000e+01,   7.70000000e+01,\n",
       "          2.70000000e+01,   5.90000000e+01,   3.60000000e+01,\n",
       "          4.50000000e+01,   2.50000000e+01,   2.00000000e+01,\n",
       "          2.10000000e+01,   3.20000000e+01,   4.90000000e+01,\n",
       "          3.20000000e+01,   3.00000000e+01,   2.80000000e+01,\n",
       "          2.90000000e+01,   1.90000000e+01,   2.30000000e+01,\n",
       "          1.10000000e+01,   2.10000000e+01,   1.20000000e+01,\n",
       "          9.57000000e+02]),\n",
       " array([-1.  , -0.98, -0.96, -0.94, -0.92, -0.9 , -0.88, -0.86, -0.84,\n",
       "        -0.82, -0.8 , -0.78, -0.76, -0.74, -0.72, -0.7 , -0.68, -0.66,\n",
       "        -0.64, -0.62, -0.6 , -0.58, -0.56, -0.54, -0.52, -0.5 , -0.48,\n",
       "        -0.46, -0.44, -0.42, -0.4 , -0.38, -0.36, -0.34, -0.32, -0.3 ,\n",
       "        -0.28, -0.26, -0.24, -0.22, -0.2 , -0.18, -0.16, -0.14, -0.12,\n",
       "        -0.1 , -0.08, -0.06, -0.04, -0.02,  0.  ,  0.02,  0.04,  0.06,\n",
       "         0.08,  0.1 ,  0.12,  0.14,  0.16,  0.18,  0.2 ,  0.22,  0.24,\n",
       "         0.26,  0.28,  0.3 ,  0.32,  0.34,  0.36,  0.38,  0.4 ,  0.42,\n",
       "         0.44,  0.46,  0.48,  0.5 ,  0.52,  0.54,  0.56,  0.58,  0.6 ,\n",
       "         0.62,  0.64,  0.66,  0.68,  0.7 ,  0.72,  0.74,  0.76,  0.78,\n",
       "         0.8 ,  0.82,  0.84,  0.86,  0.88,  0.9 ,  0.92,  0.94,  0.96,\n",
       "         0.98,  1.  ]),\n",
       " <a list of 1 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAFkCAYAAAD2auvFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFWEIkSRJRfx/VDkQYnGlY4MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f251f3ebac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.asarray(train_data['steering'], dtype=np.float32),bins=100,range=(-1,1),facecolor=\"r\", histtype = 'step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lateral_shift(image, ang):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_image(image, ang):\n",
    "    image = np.fliplr(image)\n",
    "    ang = -1 * ang\n",
    "    return (image, ang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_brightness(image):\n",
    "    bright_factor = 0.25 + np.random.uniform()\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # perform brightness augmentation only on the second channel\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    \n",
    "    # change back to RGB\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess image, \n",
    "    input: image (original shape)\n",
    "    output: image (shape is (220, 66, 3) )\n",
    "    \"\"\"    \n",
    "    image = change_brightness(image)\n",
    "    # crop shape\n",
    "    image = image[image.shape[0] * 0.34:image.shape[0] * 0.875,:,:]\n",
    "    # resize to (66, 220)\n",
    "    img = cv2.resize(image, (220, 66), interpolation=cv2.INTER_AREA)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_valid_from_path(image_path, steering_angle):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = preprocess_image(img)\n",
    "    return img, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_from_path(image_path, steering_angle):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # flip and reassign\n",
    "    random_flip_factor = np.random.randint(2)\n",
    "    if random_flip_factor == 0:\n",
    "        img, steering_angle = flip_image(img, steering_angle)\n",
    "    \n",
    "        \n",
    "    img = preprocess_image(img)\n",
    "    return img, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I created two generators, one for training data and one for validation data. In the training generator we create batches of 32 for each training sample. Therefore if I have `samples_per_epoch = 10` that means for each of those samples I yield 32 images from the training generator. I did this because it allows me to have control over what the batches turn out to be. In this case [ADD HERE]```add here I will add a probability function to pass a certain image path to the processor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_training_data(data, batch_size = 32):\n",
    "    \"\"\"\n",
    "    We create a loop through out data and \n",
    "    send out an individual row in the dataframe to preprocess_image_from_path, \n",
    "    which is then sent to preprocess_image\n",
    "    inputs: \n",
    "    data: pandas DataFrame\n",
    "    batch_size: batch sizes, size to make each batch\n",
    "    returns a yield a batch of (image_batch, label_batch)\n",
    "    \"\"\"\n",
    "    # TODO increase batch size to account for possible left, right, or center cam image\n",
    "    # TODO add correction factor possibility to \n",
    "    \n",
    "    image_batch = np.zeros((batch_size * 2, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size * 2))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            idx = np.random.randint(len(data))\n",
    "            row = data.iloc[[idx]].reset_index()\n",
    "            x, y = preprocess_image_from_path(row['center'].values[0], row['steering'].values[0])\n",
    "            \n",
    "            x2, y2 = preprocess_image_from_path(row['center'].values[0], row['steering'].values[0])\n",
    "            \n",
    "            if np.random.randint(3) == 1:\n",
    "                # 33% change to give left image and + correction_factor\n",
    "                x2, y2 = preprocess_image_from_path(row['left'].values[0], row['steering'] + 0.125)\n",
    "                \n",
    "            if np.random.randint(3) == 2:\n",
    "                # 33% change to give right image ajdn - correction_factor\n",
    "                x2, y2 = preprocess_image_from_path(row['right'].values[0], row['steering'] - 0.125)\n",
    "            \n",
    "            \n",
    "            image_batch[i] = x\n",
    "            label_batch[i] = y\n",
    "            \n",
    "            image_batch[i + 1] = x2\n",
    "            label_batch[i + 1] = y2\n",
    "            \n",
    "        yield shuffle(image_batch, label_batch)\n",
    "    \n",
    "def generate_validation_data(data):\n",
    "    \"\"\"\n",
    "    data: center camera images only, because thats what we observe (dataframe)\n",
    "    yields: one image, angle\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for idx in range(len(data)):\n",
    "            row = data.iloc[[idx]].reset_index()\n",
    "            img, angle = preprocess_image_valid_from_path(row['center'].values[0], row['steering'].values[0])\n",
    "            img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "            angle = np.array([[angle]])\n",
    "            yield img, angle\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I chose to use Nvidia's network architecture. Input (220 x 66 sized image) output (1 steering angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use the Nvidia model architecture which can be found [here add link]\n",
    "I used ELu's because they push mean unit activation functions closer to zero [https://arxiv.org/pdf/1511.07289v1.pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "\n",
    "N_img_height = 66\n",
    "N_img_width = 220\n",
    "N_img_channels = 3\n",
    "def nvidia_model():\n",
    "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalization\n",
    "    \n",
    "    # normalize only the S in HSV\n",
    "    model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = (66, 220, 3)))\n",
    "    # cropping 70 off top 25 off bottom\n",
    "    # model.add(Cropping2D(cropping=((70,25), (0, 0)))) Probably going to do cropping in my process\n",
    "\n",
    "    # subsample is strides\n",
    "    model.add(Convolution2D(24, 5, 5, \n",
    "                            subsample=(2,2), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv1'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(36, 5, 5, \n",
    "                            subsample=(2,2), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv2'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(48, 5, 5, \n",
    "                            subsample=(2,2), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, 3, 3, \n",
    "                            subsample = (1,1), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal', #gaussian init\n",
    "                            name = 'conv4'))\n",
    "    \n",
    "    model.add(ELU())              \n",
    "    model.add(Convolution2D(64, 3, 3, \n",
    "                            subsample= (1,1), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv5'))\n",
    "              \n",
    "              \n",
    "    model.add(Flatten(name = 'flatten'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100, init = 'he_normal', name = 'fc1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, init = 'he_normal', name = 'fc2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, init = 'he_normal', name = 'fc3'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    # do not put activation at the end because we want to exact output, not a class identifier\n",
    "    model.add(Dense(1, name = 'output', init = 'he_normal'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_size = len(valid_data.index)\n",
    "valid_generator = generate_validation_data(valid_data)\n",
    "BATCH = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jj/anaconda2/envs/python3/lib/python3.5/site-packages/ipykernel/__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_model()\n",
    "train_size = len(train_data.index)\n",
    "for i in range(1):\n",
    "    train_generator = generate_training_data(train_data, BATCH)\n",
    "    history = model.fit_generator(\n",
    "            train_generator, \n",
    "            samples_per_epoch = 20480, # try putting the whole thing in here in the future\n",
    "            nb_epoch = 6,\n",
    "            validation_data = valid_generator,\n",
    "            nb_val_samples = val_size)\n",
    "    print(history)\n",
    "    \n",
    "    model.save_weights('model-weightsDCLR1.h5')\n",
    "    model.save('modelDCLR1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At one point I tried to gaussian fit my data via angle distributions. Attempting this was a brutal task and I spent many many hours on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays vs Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had multiple implementations of this program. One was using numpy arrays, and the other is using dataframes. When I was using numpy arrays I had no way to nicely sort the center_turns, left_turns, and right_turns from each other because I simply concatenated them together into one large training array. I soon realized needed to separate each turn type in order to add more of some turns to balance out the histogram of steering angles. I had so many angles ~0 degrees (which is just the car going straight). Pandas dataframes were a great options for this. \n",
    "\n",
    "Originally I was just pushing all the images into an array, adding a correction factor to the left_cam images and subtracting a correction factor from the right images. However this was extremely inefficient. After choosing the pandas DataFrame method I was able to add the correction factor to left_camera and right_camera images on the fly and send them through the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Batches\n",
    "I chose to generate batches of my training data instead of yielding a single image each time so I have more control on the distribution of what gets yielded. If I was yielding an image each time, I would increase my `samples_per_epoch` in my `train_generator` to be equal to the number of sample images in my dataset. This way I simply make that a lower number and yield batches. Yielding batches also helps to avoid possible errors if I attempted to control the distribution of center_cam, left_cam, and right_cam images via probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 1:\n",
    "I already created additional data for each center_turn, left_turn, and right_turn respectively. What I attempted to do in my generator was double my batch size. From 16 to 32. \n",
    "* Immediately push in a center_cam processed image\n",
    "* 66% chance to push in another center_cam image\n",
    "* 33% chance to push in a left_cam image\n",
    "* 33% chance to push in a right_cam image\n",
    "This will allow me to introduce random left and right cam images into the dataset, creating additional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2:\n",
    "The second method was to maintain the batch size at 32 images per batch and to create a 33% chance to push a center_cam, left_cam, or right_cam\n",
    "* 33% chance for center_cam\n",
    "* 33% chance for left_cam\n",
    "* 33% chance for right_cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3:\n",
    "The third method was to maintain a batch size at 32 and only push in center images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 4:\n",
    "Increase batch size to 256 and only use center images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use the Nvidia model [https://arxiv.org/pdf/1604.07316v1.pdf]. In the preprocessing stages I converted my image from 160,320,3 to 60, 220, 3 (RGB)\n",
    "* attempt 1: I attempted to convert the image to HSV and only normalize the S channel. This turned out to [add effect]\n",
    "* attempt 2: I kept the image as RGB and fed that into the network and performed normalization on all three channels [red, green, blue]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice 1: Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice 2: No Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLu's vs ELu's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I used adam optimization and MSE\n",
    "* I used 20k samples per epoch because I have about 80k images and I do not want to sample the entire set each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to train three models sequentialls, each picking up after the next one. This is kind of like transfer learning on the same network, I am just retraining it each time with the same weights intact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting it to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this project was experimental. I would get the car to drive, and then run into some sort of wall or something. Then I would start tinkering with the preprocessing stages. I did not modify the network architecture that much other than including a dropout layer so I did not overfit my training data. The dropout layer will help me normalize and generalize to track 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_from_path(row['center'].values[0], row['steering'].values[0])\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'ang: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTrainingDataPathsCenterLeftRightPrefixGood(df, correction_factor, prefix_path):\n",
    "    \"\"\"\n",
    "    creates training data and training labels/ measurements from a data frame\n",
    "    inputs:\n",
    "    df: pandas DataFrame object\n",
    "    start: starting row to grab data\n",
    "    end: ending row to grab data\n",
    "    correction_factor: factor to correct steering angles\n",
    "    \"\"\"\n",
    "    center_images = []\n",
    "    left_images = []\n",
    "    right_images = []\n",
    "    measurements = []\n",
    "    abs_path_to_IMG = os.path.abspath(prefix_path)\n",
    "    for idx, row in df.iterrows():\n",
    "        # center images\n",
    "        center_images.append(os.path.join(abs_path_to_IMG, row['center'].strip()))\n",
    "        measurements.append(row['steering'])\n",
    "\n",
    "        # left images\n",
    "        left_images.append(os.path.join(abs_path_to_IMG, row['left'].strip()))\n",
    "        measurements.append(row['steering'] - correction_factor)\n",
    "\n",
    "        # right images\n",
    "        right_images.append(os.path.join(abs_path_to_IMG, row['right'].strip()))\n",
    "        measurements.append(row['steering'] + correction_factor)\n",
    "\n",
    "    return (np.asarray(center_images), np.asarray(left_images), np.asarray(right_images), np.asarray(measurements, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTrainingDataPathsCLR(df, correction_factor, angle_threshold = 0.15, prefix_path):\n",
    "    \"\"\"\n",
    "    creates training data and training labels/ measurements from a data frame\n",
    "    inputs:\n",
    "    df: pandas DataFrame object\n",
    "    start: starting row to grab data\n",
    "    end: ending row to grab data\n",
    "    correction_factor: factor to correct steering angles\n",
    "    \"\"\"\n",
    "    center_images = []\n",
    "    left_images = []\n",
    "    right_images = []\n",
    "    \n",
    "    center_measurements = []\n",
    "    left_measurements = []\n",
    "    right_measurements = []\n",
    "    \n",
    "    abs_path_to_IMG = os.path.abspath(prefix_path)\n",
    "    for idx, row in df.iterrows():\n",
    "        # center images\n",
    "        center_images.append(os.path.join(abs_path_to_IMG, row['center'].strip()))\n",
    "        center_measurements.append(row['steering'])\n",
    "\n",
    "\n",
    "        # left images\n",
    "        left_images.append(os.path.join(abs_path_to_IMG, row['left'].strip()))\n",
    "        left_measurements.append(row['steering'] - correction_factor)\n",
    "\n",
    "        # right images\n",
    "        right_images.append(os.path.join(abs_path_to_IMG, row['right'].strip()))\n",
    "        right_measurements.append(row['steering'] + correction_factor)\n",
    "            \n",
    "    return (\n",
    "        np.asarray(center_images),\n",
    "        np.asarray(left_images),\n",
    "        np.asarray(right_images),\n",
    "        np.asarray(center_measurements, dtype=np.float32),\n",
    "        np.asarray(left_measurements, dtype=np.float32),\n",
    "        np.asarray(right_measurements, dtype=np.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeZerosFromCenter(X, y, rang = 0.1):\n",
    "    low = -1 * rang\n",
    "    high = rang\n",
    "    is_y_in_range = np.logical_or(y <= low, y >= high)\n",
    "    X = X[is_y_in_range]\n",
    "    y = y[is_y_in_range]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeZerosFromLeft(X, y, correction_factor, rang = 0.1):\n",
    "    low = -1 * (correction_factor + rang)\n",
    "    high = -1 * (correction_factor - rang)\n",
    "    is_y_in_range = np.logical_or(y <= low, y >= high)\n",
    "    X = X[is_y_in_range]\n",
    "    y = y[is_y_in_range]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeZerosFromRight(X, y, correction_factor, rang = 0.1):\n",
    "    high = correction_factor + rang\n",
    "    low = correction_factor - rang\n",
    "    is_y_range = np.logical_or(y <= low, y >= high)\n",
    "    X = X[is_y_range]\n",
    "    y = y[is_y_range]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from udacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pd_cw2 = createDataFrame('data/driving_log.csv')\n",
    "X_train_cw2_c, X_train_cw2_l, X_train_cw2_r, y_train_cw2 = createTrainingDataPathsCenterLeftRightPrefixGood(data_pd_cw2, cf, 'data/')\n",
    "# data_pd_cw2.hist(column = 'throttle')\n",
    "X_train_udacity = np.append(X_train_cw2_c, X_train_cw2_l, axis = 0)\n",
    "X_train_udacity = np.append(X_train_udacity, X_train_cw2_r, axis = 0)\n",
    "y_train_udacity = y_train_cw2\n",
    "print('shape of X_train_udacity: ', X_train_udacity.shape)\n",
    "print('shape of y_train_udacity: ', y_train_udacity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create more udacity data \n",
    "(X_train_cw2_c, \n",
    "X_train_cw2_l, \n",
    "X_train_cw2_r, \n",
    "y_train_cw2_c,\n",
    "y_train_cw2_l,\n",
    "y_train_cw2_r) = createTrainingDataPathsCLR(data_pd_cw2, 0.15, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('X_train_cw2_c shape: ', X_train_cw2_c.shape)\n",
    "print('y_train_cw2_c shape: ', y_train_cw2_c.shape)\n",
    "print('y_train_cw2_l shape: ', X_train_cw2_l.shape)\n",
    "print('X_train_cw2_l shape: ', y_train_cw2_l.shape)\n",
    "print('X_train_cw2_r shape: ', X_train_cw2_r.shape)\n",
    "print('y_train_cw2_r shape: ', y_train_cw2_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_cw2_c, y_train_cw2_c = removeZerosFromCenter(X_train_cw2_c, y_train_cw2_c)\n",
    "X_train_cw2_l, y_train_cw2_l = removeZerosFromLeft(X_train_cw2_l, y_train_cw2_l, cf)\n",
    "X_train_cw2_r, y_train_cw2_r = removeZerosFromRight(X_train_cw2_r, y_train_cw2_r, cf)\n",
    "\n",
    "print('X_train_cw2_c shape: ', X_train_cw2_c.shape)\n",
    "print('y_train_cw2_c shape: ', y_train_cw2_c.shape)\n",
    "print('y_train_cw2_l shape: ', X_train_cw2_l.shape)\n",
    "print('X_train_cw2_l shape: ', y_train_cw2_l.shape)\n",
    "print('X_train_cw2_r shape: ', X_train_cw2_r.shape)\n",
    "print('y_train_cw2_r shape: ', y_train_cw2_r.shape)\n",
    "X_train_udacity_2 = np.append(X_train_cw2_c, X_train_cw2_l, axis = 0)\n",
    "X_train_udacity_2 = np.append(X_train_udacity_2, X_train_cw2_r, axis = 0)\n",
    "print('X_train_udacity_2 shape: ', X_train_udacity_2.shape)\n",
    "y_train_udacity_2 = np.append(y_train_cw2_c, y_train_cw2_l, axis = 0)\n",
    "y_train_udacity_2 = np.append(y_train_udacity_2, y_train_cw2_r, axis = 0)\n",
    "print('y_train_udacity_2 shape: ', y_train_udacity_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add original udacity data to filtered udacity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_udacity = np.append(X_train_udacity, X_train_udacity_2, axis = 0)\n",
    "y_train_udacity = np.append(y_train_udacity, y_train_udacity_2, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from annie recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pd_cwr2 = createDataFrame('annie_recovery/driving_log_recovery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train_cwr2_c, \n",
    "X_train_cwr2_l, \n",
    "X_train_cwr2_r, \n",
    "y_train_cwr2_c,\n",
    "y_train_cwr2_l,\n",
    "y_train_cwr2_r) = createTrainingDataPathsCLR(data_pd_cwr2, 0.15, 'annie_recovery/')\n",
    "\n",
    "X_train_cwr2_c, y_train_cwr2_c = removeZerosFromCenter(X_train_cwr2_c, y_train_cwr2_c)\n",
    "X_train_cwr2_l, y_train_cwr2_l = removeZerosFromLeft(X_train_cwr2_l, y_train_cwr2_l, cf)\n",
    "X_train_cwr2_r, y_train_cwr2_r = removeZerosFromRight(X_train_cwr2_r, y_train_cwr2_r, cf)\n",
    "\n",
    "print('X_train_cwr2_c shape: ', X_train_cwr2_c.shape)\n",
    "print('y_train_cwr2_c shape: ', y_train_cwr2_c.shape)\n",
    "print('y_train_cwr2_l shape: ', X_train_cwr2_l.shape)\n",
    "print('X_train_cwr2_l shape: ', y_train_cwr2_l.shape)\n",
    "print('X_train_cwr2_r shape: ', X_train_cwr2_r.shape)\n",
    "print('y_train_cwr2_r shape: ', y_train_cwr2_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('X_train_cwr2_c shape: ', X_train_cwr2_c.shape)\n",
    "print('y_train_cwr2_c shape: ', y_train_cwr2_c.shape)\n",
    "print('y_train_cwr2_l shape: ', X_train_cwr2_l.shape)\n",
    "print('X_train_cwr2_l shape: ', y_train_cwr2_l.shape)\n",
    "print('X_train_cwr2_r shape: ', X_train_cwr2_r.shape)\n",
    "print('y_train_cwr2_r shape: ', y_train_cwr2_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_annie = np.append(X_train_cwr2_c, X_train_cwr2_l, axis = 0)\n",
    "X_train_annie = np.append(X_train_annie, X_train_cwr2_r, axis = 0)\n",
    "print('X_train_cwr2 shape: ', X_train_annie.shape)\n",
    "y_train_annie = np.append(y_train_cwr2_c, y_train_cwr2_l, axis = 0)\n",
    "y_train_annie = np.append(y_train_annie, y_train_cwr2_r, axis = 0)\n",
    "print('y_train_cwr2 shape: ', y_train_annie.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To demonstrate acquisition function in other file and to check its correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.append(X_train_udacity, X_train_annie, axis = 0)\n",
    "y_train = np.append(y_train_udacity, y_train_annie, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from dirt recovery (ccw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pd_dirt_c1 = createDataFrame('A_Recovery_right_lane_dirt/driving_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train_dirt_c1_c, \n",
    "X_train_dirt_c1_l, \n",
    "X_train_dirt_c1_r, \n",
    "y_train_dirt_c1_c,\n",
    "y_train_dirt_c1_l,\n",
    "y_train_dirt_c1_r) = createTrainingDataPathsCLR(data_pd_dirt_c1, cf, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('X_train_dirt_c1_c shape: ', X_train_dirt_c1_c.shape)\n",
    "print('y_train_dirt_c1_c shape: ', y_train_dirt_c1_c.shape)\n",
    "print('y_train_dirt_c1_l shape: ', X_train_dirt_c1_l.shape)\n",
    "print('X_train_dirt_c1_l shape: ', y_train_dirt_c1_l.shape)\n",
    "print('X_train_dirt_c1_r shape: ', X_train_dirt_c1_r.shape)\n",
    "print('y_train_dirt_c1_r shape: ', y_train_dirt_c1_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove steering data with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dirt_c1_c, y_train_dirt_c1_c = removeZerosFromCenter(X_train_dirt_c1_c, y_train_dirt_c1_c)\n",
    "X_train_dirt_c1_l, y_train_dirt_c1_l = removeZerosFromLeft(X_train_dirt_c1_l, y_train_dirt_c1_l, cf)\n",
    "X_train_dirt_c1_r, y_train_dirt_c1_r = removeZerosFromRight(X_train_dirt_c1_r, y_train_dirt_c1_r, cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('X_train_dirt_c1_c shape: ', X_train_dirt_c1_c.shape)\n",
    "print('y_train_dirt_c1_c shape: ', y_train_dirt_c1_c.shape)\n",
    "print('y_train_dirt_c1_l shape: ', X_train_dirt_c1_l.shape)\n",
    "print('X_train_dirt_c1_l shape: ', y_train_dirt_c1_l.shape)\n",
    "print('X_train_dirt_c1_r shape: ', X_train_dirt_c1_r.shape)\n",
    "print('y_train_dirt_c1_r shape: ', y_train_dirt_c1_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "append them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dirt_c1 = np.append(X_train_dirt_c1_c, X_train_dirt_c1_l, axis = 0)\n",
    "X_train_dirt_c1 = np.append(X_train_dirt_c1, X_train_dirt_c1_r, axis = 0)\n",
    "print('X_train_dirt_c1 shape: ', X_train_dirt_c1.shape)\n",
    "y_train_dirt_c1 = np.append(y_train_dirt_c1_c, y_train_dirt_c1_l, axis = 0)\n",
    "y_train_dirt_c1 = np.append(y_train_dirt_c1, y_train_dirt_c1_r, axis = 0)\n",
    "print('y_train_dirt_c1 shape: ', y_train_dirt_c1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>=> X_train_dirt_c1, y_train_dirt_c1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from recovery_by_lake_1 (cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pd_lake_c1 = createDataFrame('recovery_cw_bylake/driving_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train_lake_c1_c, \n",
    "X_train_lake_c1_l, \n",
    "X_train_lake_c1_r, \n",
    "y_train_lake_c1_c,\n",
    "y_train_lake_c1_l,\n",
    "y_train_lake_c1_r) = createTrainingDataPathsCLR(data_pd_lake_c1, cf, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove steering data with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_lake_c1_c, y_train_lake_c1_c = removeZerosFromCenter(X_train_lake_c1_c, y_train_lake_c1_c)\n",
    "X_train_lake_c1_l, y_train_lake_c1_l = removeZerosFromLeft(X_train_lake_c1_l, y_train_lake_c1_l, cf)\n",
    "X_train_lake_c1_r, y_train_lake_c1_r = removeZerosFromRight(X_train_lake_c1_r, y_train_lake_c1_r, cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('X_train_lake_c1_c shape: ', X_train_lake_c1_c.shape)\n",
    "print('y_train_lake_c1_c shape: ', y_train_lake_c1_c.shape)\n",
    "print('y_train_lake_c1_l shape: ', X_train_lake_c1_l.shape)\n",
    "print('X_train_lake_c1_l shape: ', y_train_lake_c1_l.shape)\n",
    "print('X_train_lake_c1_r shape: ', X_train_lake_c1_r.shape)\n",
    "print('y_train_lake_c1_r shape: ', y_train_lake_c1_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "append them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_lake_c1 = np.append(X_train_lake_c1_c, X_train_lake_c1_l, axis = 0)\n",
    "X_train_lake_c1 = np.append(X_train_lake_c1, X_train_lake_c1_r, axis = 0)\n",
    "print('X_train_lake_c1 shape: ', X_train_lake_c1.shape)\n",
    "y_train_lake_c1 = np.append(y_train_lake_c1_c, y_train_lake_c1_l, axis = 0)\n",
    "y_train_lake_c1 = np.append(y_train_lake_c1, y_train_lake_c1_r, axis = 0)\n",
    "print('y_train_lake_c1 shape: ', y_train_lake_c1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>=> X_train_lake_c1, y_train_lake_c1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from recovery_by_lake_cw_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pd_lake_c2 = createDataFrame('recovery_cw_by_lake_2/driving_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train_lake_c2_c, \n",
    "X_train_lake_c2_l, \n",
    "X_train_lake_c2_r, \n",
    "y_train_lake_c2_c,\n",
    "y_train_lake_c2_l,\n",
    "y_train_lake_c2_r) = createTrainingDataPathsCLR(data_pd_lake_c2, cf, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove steering data with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_lake_c2_c, y_train_lake_c2_c = removeZerosFromCenter(X_train_lake_c2_c, y_train_lake_c2_c)\n",
    "X_train_lake_c2_l, y_train_lake_c2_l = removeZerosFromLeft(X_train_lake_c2_l, y_train_lake_c2_l, cf)\n",
    "X_train_lake_c2_r, y_train_lake_c2_r = removeZerosFromRight(X_train_lake_c2_r, y_train_lake_c2_r, cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('X_train_lake_c2_c shape: ', X_train_lake_c2_c.shape)\n",
    "print('y_train_lake_c2_c shape: ', y_train_lake_c2_c.shape)\n",
    "print('y_train_lake_c2_l shape: ', X_train_lake_c2_l.shape)\n",
    "print('X_train_lake_c2_l shape: ', y_train_lake_c2_l.shape)\n",
    "print('X_train_lake_c2_r shape: ', X_train_lake_c2_r.shape)\n",
    "print('y_train_lake_c2_r shape: ', y_train_lake_c2_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "append them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_lake_c2 = np.append(X_train_lake_c2_c, X_train_lake_c2_l, axis = 0)\n",
    "X_train_lake_c2 = np.append(X_train_lake_c2, X_train_lake_c2_r, axis = 0)\n",
    "print('X_train_lake_c2 shape: ', X_train_lake_c2.shape)\n",
    "y_train_lake_c2 = np.append(y_train_lake_c2_c, y_train_lake_c2_l, axis = 0)\n",
    "y_train_lake_c2 = np.append(y_train_lake_c2, y_train_lake_c2_r, axis = 0)\n",
    "print('y_train_lake_c2 shape: ', y_train_lake_c2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>=> X_train_lake_c2, y_train_lake_c2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from ken dirt recovery_set1 (dirt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pd_dirt2_cw = createDataFrame('controller_dirt_track1_set1_cw/driving_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train_dirt2_cw_c, \n",
    "X_train_dirt2_cw_l, \n",
    "X_train_dirt2_cw_r, \n",
    "y_train_dirt2_cw_c,\n",
    "y_train_dirt2_cw_l,\n",
    "y_train_dirt2_cw_r) = createTrainingDataPathsCLR(data_pd_dirt2_cw, 0.15, 'controller_dirt_track1_set1_cw/')\n",
    "\n",
    "X_train_dirt2_cw_c, y_train_dirt2_cw_c = removeZerosFromCenter(X_train_dirt2_cw_c, y_train_dirt2_cw_c)\n",
    "X_train_dirt2_cw_l, y_train_dirt2_cw_l = removeZerosFromLeft(X_train_dirt2_cw_l, y_train_dirt2_cw_l, cf)\n",
    "X_train_dirt2_cw_r, y_train_dirt2_cw_r = removeZerosFromRight(X_train_dirt2_cw_r, y_train_dirt2_cw_r, cf)\n",
    "\n",
    "print('X_train_dirt2_cw_c shape: ', X_train_dirt2_cw_c.shape)\n",
    "print('y_train_dirt2_cw_c shape: ', y_train_dirt2_cw_c.shape)\n",
    "print('y_train_dirt2_cw_l shape: ', X_train_dirt2_cw_l.shape)\n",
    "print('X_train_dirt2_cw_l shape: ', y_train_dirt2_cw_l.shape)\n",
    "print('X_train_dirt2_cw_r shape: ', X_train_dirt2_cw_r.shape)\n",
    "print('y_train_dirt2_cw_r shape: ', y_train_dirt2_cw_r.shape)\n",
    "\n",
    "X_train_dirt2_cw = np.append(X_train_dirt2_cw_c, X_train_dirt2_cw_l, axis = 0)\n",
    "X_train_dirt2_cw = np.append(X_train_dirt2_cw, X_train_dirt2_cw_r, axis = 0)\n",
    "print('X_train_dirt2_cw shape: ', X_train_dirt2_cw.shape)\n",
    "y_train_dirt2_cw = np.append(y_train_dirt2_cw_c, y_train_dirt2_cw_l, axis = 0)\n",
    "y_train_dirt2_cw = np.append(y_train_dirt2_cw, y_train_dirt2_cw_r, axis = 0)\n",
    "print('y_train_dirt2_cw shape: ', y_train_dirt2_cw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>=> X_train_dirt2_cw, y_train_dirt2_cw</font>#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from ken dirt recovery_set2 (dirt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pd_dirt3_cw = createDataFrame('controller_dirt_track1_set2_cw/driving_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train_dirt3_cw_c, \n",
    "X_train_dirt3_cw_l, \n",
    "X_train_dirt3_cw_r, \n",
    "y_train_dirt3_cw_c,\n",
    "y_train_dirt3_cw_l,\n",
    "y_train_dirt3_cw_r) = createTrainingDataPathsCLR(data_pd_dirt3_cw, 0.15, 'controller_dirt_track1_set2_cw/')\n",
    "\n",
    "X_train_dirt3_cw_c, y_train_dirt3_cw_c = removeZerosFromCenter(X_train_dirt3_cw_c, y_train_dirt3_cw_c)\n",
    "X_train_dirt3_cw_l, y_train_dirt3_cw_l = removeZerosFromLeft(X_train_dirt3_cw_l, y_train_dirt3_cw_l, cf)\n",
    "X_train_dirt3_cw_r, y_train_dirt3_cw_r = removeZerosFromRight(X_train_dirt3_cw_r, y_train_dirt3_cw_r, cf)\n",
    "\n",
    "print('X_train_dirt3_cw_c shape: ', X_train_dirt3_cw_c.shape)\n",
    "print('y_train_dirt3_cw_c shape: ', y_train_dirt3_cw_c.shape)\n",
    "print('y_train_dirt3_cw_l shape: ', X_train_dirt3_cw_l.shape)\n",
    "print('X_train_dirt3_cw_l shape: ', y_train_dirt3_cw_l.shape)\n",
    "print('X_train_dirt3_cw_r shape: ', X_train_dirt3_cw_r.shape)\n",
    "print('y_train_dirt3_cw_r shape: ', y_train_dirt3_cw_r.shape)\n",
    "\n",
    "X_train_dirt3_cw = np.append(X_train_dirt3_cw_c, X_train_dirt3_cw_l, axis = 0)\n",
    "X_train_dirt3_cw = np.append(X_train_dirt3_cw, X_train_dirt3_cw_r, axis = 0)\n",
    "print('X_train_dirt3_cw shape: ', X_train_dirt3_cw.shape)\n",
    "y_train_dirt3_cw = np.append(y_train_dirt3_cw_c, y_train_dirt3_cw_l, axis = 0)\n",
    "y_train_dirt3_cw = np.append(y_train_dirt3_cw, y_train_dirt3_cw_r, axis = 0)\n",
    "print('y_train_dirt3_cw shape: ', y_train_dirt3_cw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from turn before bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pd_bridge = createDataFrame('turn_before_bridge/driving_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train_bridge_c, \n",
    "X_train_bridge_l, \n",
    "X_train_bridge_r, \n",
    "y_train_bridge_c,\n",
    "y_train_bridge_l,\n",
    "y_train_bridge_r) = createTrainingDataPathsCLR(data_pd_bridge, 0.15, '.')\n",
    "\n",
    "X_train_bridge_c, y_train_bridge_c = removeZerosFromCenter(X_train_bridge_c, y_train_bridge_c)\n",
    "X_train_bridge_l, y_train_bridge_l = removeZerosFromLeft(X_train_bridge_l, y_train_bridge_l, cf)\n",
    "X_train_bridge_r, y_train_bridge_r = removeZerosFromRight(X_train_bridge_r, y_train_bridge_r, cf)\n",
    "\n",
    "print('X_train_bridge_c shape: ', X_train_bridge_c.shape)\n",
    "print('y_train_bridge_c shape: ', y_train_bridge_c.shape)\n",
    "print('y_train_bridge_l shape: ', X_train_bridge_l.shape)\n",
    "print('X_train_bridge_l shape: ', y_train_bridge_l.shape)\n",
    "print('X_train_bridge_r shape: ', X_train_bridge_r.shape)\n",
    "print('y_train_bridge_r shape: ', y_train_bridge_r.shape)\n",
    "\n",
    "X_train_bridge = np.append(X_train_bridge_c, X_train_bridge_l, axis = 0)\n",
    "X_train_bridge = np.append(X_train_bridge, X_train_bridge_r, axis = 0)\n",
    "print('X_train_bridge shape: ', X_train_bridge.shape)\n",
    "y_train_bridge = np.append(y_train_bridge_c, y_train_bridge_l, axis = 0)\n",
    "y_train_bridge = np.append(y_train_bridge, y_train_bridge_r, axis = 0)\n",
    "print('y_train_cwr2 shape: ', y_train_bridge.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>=> X_train_dirt3_cw, y_train_dirt3_cw</font>#"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
